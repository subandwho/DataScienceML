{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-02-01T07:46:38.001585Z","iopub.execute_input":"2023-02-01T07:46:38.002086Z","iopub.status.idle":"2023-02-01T07:46:38.007686Z","shell.execute_reply.started":"2023-02-01T07:46:38.002042Z","shell.execute_reply":"2023-02-01T07:46:38.006710Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-01T10:27:20.145782Z","iopub.execute_input":"2023-02-01T10:27:20.146190Z","iopub.status.idle":"2023-02-01T10:27:20.183321Z","shell.execute_reply.started":"2023-02-01T10:27:20.146108Z","shell.execute_reply":"2023-02-01T10:27:20.182237Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\n/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\n/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:27:20.185527Z","iopub.execute_input":"2023-02-01T10:27:20.185930Z","iopub.status.idle":"2023-02-01T10:27:20.301003Z","shell.execute_reply.started":"2023-02-01T10:27:20.185874Z","shell.execute_reply":"2023-02-01T10:27:20.299874Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                 id     anchor                  target context  score\n0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:27:20.302904Z","iopub.execute_input":"2023-02-01T10:27:20.303300Z","iopub.status.idle":"2023-02-01T10:27:20.311403Z","shell.execute_reply.started":"2023-02-01T10:27:20.303262Z","shell.execute_reply":"2023-02-01T10:27:20.310117Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(36473, 5)"},"metadata":{}}]},{"cell_type":"code","source":"data.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:27:20.314596Z","iopub.execute_input":"2023-02-01T10:27:20.315495Z","iopub.status.idle":"2023-02-01T10:27:20.379635Z","shell.execute_reply.started":"2023-02-01T10:27:20.315451Z","shell.execute_reply":"2023-02-01T10:27:20.378590Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     37d61fd2272659b1  component composite coating  composition     H01\nfreq                   1                          152           24    2186","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36473</td>\n      <td>733</td>\n      <td>29340</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>37d61fd2272659b1</td>\n      <td>component composite coating</td>\n      <td>composition</td>\n      <td>H01</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>152</td>\n      <td>24</td>\n      <td>2186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['input'] = 'TEXT1:'+ data.context + 'TEXT2:' + data.target + 'ANC:' + data.anchor\ndata.input.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:27:20.380983Z","iopub.execute_input":"2023-02-01T10:27:20.383119Z","iopub.status.idle":"2023-02-01T10:27:20.411595Z","shell.execute_reply.started":"2023-02-01T10:27:20.383076Z","shell.execute_reply":"2023-02-01T10:27:20.410394Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0    TEXT1:A47TEXT2:abatement of pollutionANC:abate...\n1           TEXT1:A47TEXT2:act of abatingANC:abatement\n2          TEXT1:A47TEXT2:active catalystANC:abatement\n3      TEXT1:A47TEXT2:eliminating processANC:abatement\n4            TEXT1:A47TEXT2:forest regionANC:abatement\n5         TEXT1:A47TEXT2:greenhouse gasesANC:abatement\n6           TEXT1:A47TEXT2:increased rateANC:abatement\n7        TEXT1:A47TEXT2:measurement levelANC:abatement\n8        TEXT1:A47TEXT2:minimising soundsANC:abatement\n9    TEXT1:A47TEXT2:mixing core materialsANC:abatement\nName: input, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\ndf = Dataset.from_pandas(data)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:27:20.413663Z","iopub.execute_input":"2023-02-01T10:27:20.414115Z","iopub.status.idle":"2023-02-01T10:27:21.435174Z","shell.execute_reply.started":"2023-02-01T10:27:20.414011Z","shell.execute_reply":"2023-02-01T10:27:21.433906Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"},"metadata":{}}]},{"cell_type":"code","source":"model = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:52:58.273181Z","iopub.execute_input":"2023-02-01T10:52:58.273591Z","iopub.status.idle":"2023-02-01T10:52:58.278650Z","shell.execute_reply.started":"2023-02-01T10:52:58.273558Z","shell.execute_reply":"2023-02-01T10:52:58.277360Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\ntokenz = AutoTokenizer.from_pretrained(model, padding='max_len')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:52:58.634575Z","iopub.execute_input":"2023-02-01T10:52:58.635233Z","iopub.status.idle":"2023-02-01T10:53:01.314623Z","shell.execute_reply.started":"2023-02-01T10:52:58.635192Z","shell.execute_reply":"2023-02-01T10:53:01.313612Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\nModel config DebertaV2Config {\n  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/spm.model from cache at /root/.cache/huggingface/transformers/3ed0740946d0a60434dd6a0c940068899c0b48bb5caba7d60c1db454877c64a3.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\nloading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer.json from cache at None\nloading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/b40830d1301d39fdc8c6a059787f7f46b8786c252b5475512aa5cf0a66020075.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\nloading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\nModel config DebertaV2Config {\n  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nAdding [MASK] to the vocabulary\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nloading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\nModel config DebertaV2Config {\n  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenz.tokenize('Hi! I am really excited about the $uperman: Legacy film for the DCU')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:01.316974Z","iopub.execute_input":"2023-02-01T10:53:01.317387Z","iopub.status.idle":"2023-02-01T10:53:01.325129Z","shell.execute_reply.started":"2023-02-01T10:53:01.317348Z","shell.execute_reply":"2023-02-01T10:53:01.324109Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"['▁Hi',\n '!',\n '▁I',\n '▁am',\n '▁really',\n '▁excited',\n '▁about',\n '▁the',\n '▁$',\n 'up',\n 'erman',\n ':',\n '▁Legacy',\n '▁film',\n '▁for',\n '▁the',\n '▁DCU']"},"metadata":{}}]},{"cell_type":"code","source":"tokenz.tokenize('Okay, but will Ras Al Ghul or Slade Wilson conjure up in Brave and the Bold????')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:01.326657Z","iopub.execute_input":"2023-02-01T10:53:01.327010Z","iopub.status.idle":"2023-02-01T10:53:01.339276Z","shell.execute_reply.started":"2023-02-01T10:53:01.326976Z","shell.execute_reply":"2023-02-01T10:53:01.338123Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"['▁Okay',\n ',',\n '▁but',\n '▁will',\n '▁Ras',\n '▁Al',\n '▁G',\n 'hul',\n '▁or',\n '▁Slade',\n '▁Wilson',\n '▁conjure',\n '▁up',\n '▁in',\n '▁Brave',\n '▁and',\n '▁the',\n '▁Bold',\n '?',\n '?',\n '?',\n '?']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(x): \n    return tokenz(x['input'])","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:01.341756Z","iopub.execute_input":"2023-02-01T10:53:01.342150Z","iopub.status.idle":"2023-02-01T10:53:01.348878Z","shell.execute_reply.started":"2023-02-01T10:53:01.342116Z","shell.execute_reply":"2023-02-01T10:53:01.347851Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"tok_df = df.map(tokenize, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:01.442343Z","iopub.execute_input":"2023-02-01T10:53:01.442987Z","iopub.status.idle":"2023-02-01T10:53:03.886937Z","shell.execute_reply.started":"2023-02-01T10:53:01.442948Z","shell.execute_reply":"2023-02-01T10:53:03.886016Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c50625a9a484c64bc1817dc912dbf14"}},"metadata":{}}]},{"cell_type":"code","source":"row = tok_df[0]\nrow['input'], row['input_ids']","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:03.889014Z","iopub.execute_input":"2023-02-01T10:53:03.889391Z","iopub.status.idle":"2023-02-01T10:53:03.898791Z","shell.execute_reply.started":"2023-02-01T10:53:03.889354Z","shell.execute_reply":"2023-02-01T10:53:03.897763Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"('TEXT1:A47TEXT2:abatement of pollutionANC:abatement',\n [1,\n  54453,\n  435,\n  294,\n  558,\n  5753,\n  104917,\n  445,\n  294,\n  16191,\n  297,\n  17019,\n  265,\n  6435,\n  64097,\n  294,\n  16191,\n  297,\n  17019,\n  2])"},"metadata":{}}]},{"cell_type":"code","source":"tok_df = tok_df.rename_columns({'score':'labels'})","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:03.900721Z","iopub.execute_input":"2023-02-01T10:53:03.901136Z","iopub.status.idle":"2023-02-01T10:53:03.909778Z","shell.execute_reply.started":"2023-02-01T10:53:03.901097Z","shell.execute_reply":"2023-02-01T10:53:03.908803Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv')\ntest_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:03.912295Z","iopub.execute_input":"2023-02-01T10:53:03.913056Z","iopub.status.idle":"2023-02-01T10:53:03.936677Z","shell.execute_reply.started":"2023-02-01T10:53:03.913022Z","shell.execute_reply":"2023-02-01T10:53:03.935890Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"                      id      anchor                         target context\ncount                 36          36                             36      36\nunique                36          34                             36      29\ntop     4112d61851461f60  el display  inorganic photoconductor drum     G02\nfreq                   1           2                              1       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>34</td>\n      <td>36</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>4112d61851461f60</td>\n      <td>el display</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dds = tok_df.train_test_split(0.25, seed=42)\ndds","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:03.938202Z","iopub.execute_input":"2023-02-01T10:53:03.938958Z","iopub.status.idle":"2023-02-01T10:53:03.958241Z","shell.execute_reply.started":"2023-02-01T10:53:03.938919Z","shell.execute_reply":"2023-02-01T10:53:03.957472Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"test_df['input'] = 'TEXT1:'+ test_df.context + 'TEXT2:' + test_df.target + 'ANC:' + test_df.anchor\ntest_df = Dataset.from_pandas(test_df).map(tokenize, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:04.322275Z","iopub.execute_input":"2023-02-01T10:53:04.324122Z","iopub.status.idle":"2023-02-01T10:53:04.383526Z","shell.execute_reply.started":"2023-02-01T10:53:04.324074Z","shell.execute_reply":"2023-02-01T10:53:04.382460Z"},"trusted":true},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44655696d0b416fbbf861dc6fc2007f"}},"metadata":{}}]},{"cell_type":"code","source":"def corr(x,y):\n    return np.corrcoef(x,y)[0][1]","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:04.924749Z","iopub.execute_input":"2023-02-01T10:53:04.926155Z","iopub.status.idle":"2023-02-01T10:53:04.931805Z","shell.execute_reply.started":"2023-02-01T10:53:04.926104Z","shell.execute_reply":"2023-02-01T10:53:04.930384Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"def corr_d(test_df):\n    return {'pearson': corr(*test_df)}","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:05.425178Z","iopub.execute_input":"2023-02-01T10:53:05.426057Z","iopub.status.idle":"2023-02-01T10:53:05.432592Z","shell.execute_reply.started":"2023-02-01T10:53:05.426000Z","shell.execute_reply":"2023-02-01T10:53:05.430442Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:05.968138Z","iopub.execute_input":"2023-02-01T10:53:05.968504Z","iopub.status.idle":"2023-02-01T10:53:05.974160Z","shell.execute_reply.started":"2023-02-01T10:53:05.968474Z","shell.execute_reply":"2023-02-01T10:53:05.972852Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nbs = 128\nepochs=4\nlr = 7e-5","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:06.399151Z","iopub.execute_input":"2023-02-01T10:53:06.401124Z","iopub.status.idle":"2023-02-01T10:53:06.407140Z","shell.execute_reply.started":"2023-02-01T10:53:06.401081Z","shell.execute_reply":"2023-02-01T10:53:06.405993Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1,\n                         lr_scheduler_type='cosine', fp16 = True,\n                         evaluation_strategy='epoch', per_device_train_batch_size=bs,\n                         per_device_eval_batch_size=bs*2, num_train_epochs=epochs,\n                         weight_decay=0.01, report_to='none'\n                        )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:53:06.980075Z","iopub.execute_input":"2023-02-01T10:53:06.980777Z","iopub.status.idle":"2023-02-01T10:53:06.989678Z","shell.execute_reply.started":"2023-02-01T10:53:06.980737Z","shell.execute_reply":"2023-02-01T10:53:06.988567Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\n","output_type":"stream"}]},{"cell_type":"code","source":"model_x = AutoModelForSequenceClassification.from_pretrained(model, num_labels=1)\ntrainer = Trainer(model_x, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                 tokenizer=tokenz, compute_metrics=corr_d)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:55:52.315541Z","iopub.execute_input":"2023-02-01T10:55:52.315941Z","iopub.status.idle":"2023-02-01T10:55:54.253532Z","shell.execute_reply.started":"2023-02-01T10:55:52.315909Z","shell.execute_reply":"2023-02-01T10:55:54.252643Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\nModel config DebertaV2Config {\n  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ce3185000148731a86ceaf533caa85fe513fc79e02b7fe5831fb1ed52a0e0d22.7e73b1561275ae3b633ba76ab7e4889d28d73dbcdc008cbc2414369b39da319b\nSome weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:55:54.817961Z","iopub.execute_input":"2023-02-01T10:55:54.818328Z","iopub.status.idle":"2023-02-01T10:58:47.408687Z","shell.execute_reply.started":"2023-02-01T10:55:54.818297Z","shell.execute_reply":"2023-02-01T10:58:47.407296Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 27354\n  Num Epochs = 4\n  Instantaneous batch size per device = 128\n  Total train batch size (w. parallel, distributed & accumulation) = 256\n  Gradient Accumulation steps = 1\n  Total optimization steps = 428\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [428/428 02:46, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.030082</td>\n      <td>0.756549</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.026892</td>\n      <td>0.799371</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.027595</td>\n      <td>0.806051</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.025550</td>\n      <td>0.811190</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 512\nThe following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 512\nThe following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 512\nThe following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 512\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=428, training_loss=0.03395047811704261, metrics={'train_runtime': 172.5605, 'train_samples_per_second': 634.073, 'train_steps_per_second': 2.48, 'total_flos': 676715015824740.0, 'train_loss': 0.03395047811704261, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"preds = trainer.predict(test_df).predictions.astype('float')\npreds = np.clip(preds, 0,1)\npreds","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:59:51.848160Z","iopub.execute_input":"2023-02-01T10:59:51.848551Z","iopub.status.idle":"2023-02-01T10:59:51.966282Z","shell.execute_reply.started":"2023-02-01T10:59:51.848519Z","shell.execute_reply":"2023-02-01T10:59:51.965387Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stderr","text":"The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: anchor, target, id, input, context. If anchor, target, id, input, context are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"array([[0.57861328],\n       [0.77734375],\n       [0.50976562],\n       [0.42016602],\n       [0.10113525],\n       [0.64013672],\n       [0.54296875],\n       [0.        ],\n       [0.28515625],\n       [1.        ],\n       [0.37597656],\n       [0.30175781],\n       [0.71142578],\n       [0.68359375],\n       [0.80078125],\n       [0.53466797],\n       [0.29663086],\n       [0.        ],\n       [0.64892578],\n       [0.36474609],\n       [0.32275391],\n       [0.17651367],\n       [0.03182983],\n       [0.27050781],\n       [0.59619141],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.70214844],\n       [0.33349609],\n       [0.00930786],\n       [0.73388672],\n       [0.54345703],\n       [0.46557617],\n       [0.20336914]])"},"metadata":{}}]}]}