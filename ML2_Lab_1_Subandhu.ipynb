{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dBFlXZjkcb1"
   },
   "source": [
    "# Machine Learning Lab 2\n",
    "\n",
    "## Assignment 2 (Deadline : 22/01/2023 11:59PM)\n",
    "\n",
    "Total Points : 25\n",
    "\n",
    "Your answers must be entered in LMS by midnight of the day it is due. \n",
    "\n",
    "If the question requires a textual response, you can create a PDF and upload that. \n",
    "\n",
    "The PDF might be generated from MS-WORD, LATEX, the image of a hand- written response, or using any other mechanism. \n",
    "\n",
    "Code must be uploaded and may require demonstration to the TA. \n",
    "\n",
    "Numbers in the parentheses indicate points allocated to the question. \n",
    "\n",
    "**Naming Convention**: FirstName_LastName_Lab1_TLP23.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXZ8Hvxgk6Xx"
   },
   "source": [
    "# Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWdrmwpmk8D-"
   },
   "source": [
    "We want to design a system that can help a visually impaired person\n",
    "know what is around them. At present, they use a “white cane” that\n",
    "is used to tap and feel is there is an obstacle. We want to use machine learning to make life slightly better for them. However, given the\n",
    "limitation of time we will consider a subset, though a core part of the\n",
    "problem.\n",
    "\n",
    "The posture we will adopt is that the mobile phone camera can acquire\n",
    "images at some periodic intervals or when the individual wants to know\n",
    "what is in the field of view of where the camera is being pointed. Assume that there are only 10 objects that are there in the world (there\n",
    "is no class which is “everything else”) and the field of view may contain\n",
    "one of those 10 objects.\n",
    "\n",
    "The image is fed into a network that you have to design that can\n",
    "recognize what the object is. Hopefully, a speech synthesizer can then\n",
    "announce it to the individual but we will not concern ourselves with\n",
    "the speech synthesis part.\n",
    "\n",
    "Use the CIFAR-10 dataset https://www.cs.toronto.edu/~kriz/cifar.\n",
    "html. This dataset has 10 objects and each image has an object. In\n",
    "a real system we will have to contend with segmentation problem but\n",
    "let us assume that step has been done for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xac7EXCElA7t"
   },
   "source": [
    "Design a FCNN using\n",
    " \n",
    "*   a single layer **(7 points)**\n",
    "\n",
    "*   multiple layers in lower dimension, and **(7 points)**\n",
    "\n",
    "*   a deep FCNN **(7 points)**\n",
    "\n",
    "\n",
    "that can recognize the object (the category can be fed into a speech synthesizer\n",
    "that can announce the object in the filed of view but that is not part of\n",
    "the scope). Report the 5-fold cross validation accuracy for the third deep FCNN  and comment\n",
    "on some practical difficulties that you may face in implement this on a\n",
    "mobile phone **(4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "     --------------------------------------- 23.2/23.2 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     ------------------------------------- 439.2/439.2 kB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.6)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 14.2 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 126.5/126.5 kB ? eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 15.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (20.1)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.11.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (45.2.0.post20200210)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "     ------------------------------------- 896.6/896.6 kB 14.3 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.1-cp37-cp37m-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 16.9 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.34.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------- 232.7/232.7 kB 13.9 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "     ---------------------------------------- 177.8/177.8 kB ? eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB ? eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ------------------------------------- 781.3/781.3 kB 16.4 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.6)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.8)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp37-cp37m-win_amd64.whl (16 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, MarkupSafe, keras, importlib-metadata, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.5.0\n",
      "    Uninstalling importlib-metadata-1.5.0:\n",
      "      Successfully uninstalled importlib-metadata-1.5.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.0\n",
      "    Uninstalling Werkzeug-1.0.0:\n",
      "      Successfully uninstalled Werkzeug-1.0.0\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.2.1 flatbuffers-23.1.4 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 importlib-metadata-6.0.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0 werkzeug-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "argcomplete 2.0.0 requires importlib-metadata<5,>=0.23; python_version == \"3.7\", but you have importlib-metadata 6.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K__xnM1LkbeT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# flatten the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s 339us/sample - loss: 1.9660 - accuracy: 0.3146 - val_loss: 1.9222 - val_accuracy: 0.3452\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 9s 178us/sample - loss: 1.8856 - accuracy: 0.3516 - val_loss: 2.0887 - val_accuracy: 0.3111\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 7s 147us/sample - loss: 1.8561 - accuracy: 0.3635 - val_loss: 1.9252 - val_accuracy: 0.3510\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 1.8372 - accuracy: 0.3704 - val_loss: 1.8115 - val_accuracy: 0.3773\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 7s 132us/sample - loss: 1.8283 - accuracy: 0.3736 - val_loss: 1.8842 - val_accuracy: 0.3399\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 7s 132us/sample - loss: 1.8268 - accuracy: 0.3753 - val_loss: 1.8058 - val_accuracy: 0.3668\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 1.8142 - accuracy: 0.3788 - val_loss: 1.9300 - val_accuracy: 0.3557\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 128us/sample - loss: 1.8137 - accuracy: 0.3823 - val_loss: 1.9976 - val_accuracy: 0.3323\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 1.8024 - accuracy: 0.3863 - val_loss: 1.8692 - val_accuracy: 0.3657\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 1.8082 - accuracy: 0.3841 - val_loss: 1.8455 - val_accuracy: 0.3606\n",
      "Test accuracy: 0.3606\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 32*32*3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32*32*3)\n",
    "\n",
    "# normalize the pixel values\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# create the model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='softmax', input_shape=(3072,)))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=3)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 10s 210us/sample - loss: 2.0918 - accuracy: 0.1794 - val_loss: 2.0542 - val_accuracy: 0.1921\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 7s 139us/sample - loss: 2.0450 - accuracy: 0.1959 - val_loss: 2.0301 - val_accuracy: 0.1944\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 2.0391 - accuracy: 0.2003 - val_loss: 2.0309 - val_accuracy: 0.1999\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 5s 109us/sample - loss: 2.0322 - accuracy: 0.2032 - val_loss: 2.0260 - val_accuracy: 0.2063\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 2.0319 - accuracy: 0.2051 - val_loss: 2.0639 - val_accuracy: 0.1953\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 5s 98us/sample - loss: 2.0296 - accuracy: 0.2051 - val_loss: 2.0280 - val_accuracy: 0.2084\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 5s 94us/sample - loss: 2.0295 - accuracy: 0.2047 - val_loss: 2.0265 - val_accuracy: 0.2029\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 5s 94us/sample - loss: 2.0262 - accuracy: 0.2067 - val_loss: 2.0206 - val_accuracy: 0.2097\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 2.0262 - accuracy: 0.2046 - val_loss: 2.0161 - val_accuracy: 0.2081\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 2.0260 - accuracy: 0.2071 - val_loss: 2.0144 - val_accuracy: 0.2057\n",
      "Test accuracy: 0.2057\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Dense(10, activation='relu', input_shape=(3072,)))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model2.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model on the test data\n",
    "test_loss, test_acc = model2.evaluate(x_test, y_test, verbose=3)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 50s 1ms/sample - loss: 2.0785 - accuracy: 0.1818 - val_loss: 2.0067 - val_accuracy: 0.1936\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 40s 1ms/sample - loss: 1.9750 - accuracy: 0.2290 - val_loss: 1.8834 - val_accuracy: 0.2765\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 39s 984us/sample - loss: 1.8641 - accuracy: 0.2914 - val_loss: 1.8505 - val_accuracy: 0.3007\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 39s 985us/sample - loss: 1.8159 - accuracy: 0.3109 - val_loss: 1.8056 - val_accuracy: 0.3213\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 39s 984us/sample - loss: 1.7837 - accuracy: 0.3312 - val_loss: 1.7667 - val_accuracy: 0.3398\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 39s 980us/sample - loss: 1.7520 - accuracy: 0.3497 - val_loss: 1.7219 - val_accuracy: 0.3632\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 39s 985us/sample - loss: 1.7291 - accuracy: 0.3582 - val_loss: 1.7324 - val_accuracy: 0.3546\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 40s 1ms/sample - loss: 1.7062 - accuracy: 0.3704 - val_loss: 1.6955 - val_accuracy: 0.3730\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 40s 994us/sample - loss: 1.6897 - accuracy: 0.3793 - val_loss: 1.7099 - val_accuracy: 0.3637\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 39s 982us/sample - loss: 1.6711 - accuracy: 0.3857 - val_loss: 1.6979 - val_accuracy: 0.3867\n",
      "10000/10000 [==============================] - 6s 574us/sample - loss: 1.6979 - accuracy: 0.3867\n",
      "Fold validation loss:  1.6978541410446166\n",
      "Fold validation accuracy:  0.3867\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 42s 1ms/sample - loss: 1.6627 - accuracy: 0.3905 - val_loss: 1.6800 - val_accuracy: 0.3842\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 37s 930us/sample - loss: 1.6398 - accuracy: 0.4013 - val_loss: 1.6650 - val_accuracy: 0.4038\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 38s 939us/sample - loss: 1.6252 - accuracy: 0.4084 - val_loss: 1.6781 - val_accuracy: 0.3925\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 37s 924us/sample - loss: 1.6123 - accuracy: 0.4138 - val_loss: 1.6283 - val_accuracy: 0.4111\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 37s 924us/sample - loss: 1.5998 - accuracy: 0.4205 - val_loss: 1.6476 - val_accuracy: 0.4085\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 38s 947us/sample - loss: 1.5890 - accuracy: 0.4255 - val_loss: 1.6311 - val_accuracy: 0.4153\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 39s 963us/sample - loss: 1.5788 - accuracy: 0.4303 - val_loss: 1.6682 - val_accuracy: 0.4111\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 37s 934us/sample - loss: 1.5685 - accuracy: 0.4341 - val_loss: 1.6117 - val_accuracy: 0.4250\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 37s 936us/sample - loss: 1.5548 - accuracy: 0.4419 - val_loss: 1.6844 - val_accuracy: 0.4051\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 37s 930us/sample - loss: 1.5512 - accuracy: 0.4401 - val_loss: 1.6762 - val_accuracy: 0.3996\n",
      "10000/10000 [==============================] - 4s 366us/sample - loss: 1.6762 - accuracy: 0.3996\n",
      "Fold validation loss:  1.6761625049591065\n",
      "Fold validation accuracy:  0.3996\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 41s 1ms/sample - loss: 1.5616 - accuracy: 0.4401 - val_loss: 1.5369 - val_accuracy: 0.4470\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 37s 920us/sample - loss: 1.5479 - accuracy: 0.4440 - val_loss: 1.5696 - val_accuracy: 0.4303\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 39s 970us/sample - loss: 1.5439 - accuracy: 0.4466 - val_loss: 1.5492 - val_accuracy: 0.4399\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 42s 1ms/sample - loss: 1.5378 - accuracy: 0.4490 - val_loss: 1.5439 - val_accuracy: 0.4391\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 37s 936us/sample - loss: 1.5196 - accuracy: 0.4536 - val_loss: 1.5207 - val_accuracy: 0.4512\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 37s 928us/sample - loss: 1.5150 - accuracy: 0.4579 - val_loss: 1.5192 - val_accuracy: 0.4553\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 38s 940us/sample - loss: 1.5065 - accuracy: 0.4592 - val_loss: 1.5472 - val_accuracy: 0.4553\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 35s 873us/sample - loss: 1.4953 - accuracy: 0.4659 - val_loss: 1.6095 - val_accuracy: 0.4260\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 34s 845us/sample - loss: 1.4895 - accuracy: 0.4675 - val_loss: 1.5630 - val_accuracy: 0.4472\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 35s 871us/sample - loss: 1.4835 - accuracy: 0.4699 - val_loss: 1.5488 - val_accuracy: 0.4559\n",
      "10000/10000 [==============================] - 4s 387us/sample - loss: 1.5488 - accuracy: 0.4559\n",
      "Fold validation loss:  1.5487907726287842\n",
      "Fold validation accuracy:  0.4559\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 37s 924us/sample - loss: 1.4956 - accuracy: 0.4656 - val_loss: 1.4665 - val_accuracy: 0.4735\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 32s 794us/sample - loss: 1.4837 - accuracy: 0.4714 - val_loss: 1.4618 - val_accuracy: 0.4780\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 33s 813us/sample - loss: 1.4726 - accuracy: 0.4722 - val_loss: 1.5018 - val_accuracy: 0.4607\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 34s 852us/sample - loss: 1.4699 - accuracy: 0.4739 - val_loss: 1.4937 - val_accuracy: 0.4653\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 35s 866us/sample - loss: 1.4527 - accuracy: 0.4790 - val_loss: 1.5490 - val_accuracy: 0.4495\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 34s 858us/sample - loss: 1.4511 - accuracy: 0.4797 - val_loss: 1.5129 - val_accuracy: 0.4593\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 35s 882us/sample - loss: 1.4397 - accuracy: 0.4849 - val_loss: 1.5225 - val_accuracy: 0.4576\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 33s 835us/sample - loss: 1.4264 - accuracy: 0.4892 - val_loss: 1.5221 - val_accuracy: 0.4546\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 34s 847us/sample - loss: 1.4239 - accuracy: 0.4902 - val_loss: 1.5152 - val_accuracy: 0.4663\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 38s 948us/sample - loss: 1.4113 - accuracy: 0.4943 - val_loss: 1.5934 - val_accuracy: 0.4436\n",
      "10000/10000 [==============================] - 4s 395us/sample - loss: 1.5934 - accuracy: 0.4436\n",
      "Fold validation loss:  1.5933747863769532\n",
      "Fold validation accuracy:  0.4436\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 1.4525 - accuracy: 0.4815 - val_loss: 1.4421 - val_accuracy: 0.4858\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 35s 874us/sample - loss: 1.4326 - accuracy: 0.4862 - val_loss: 1.4033 - val_accuracy: 0.5014\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 33s 830us/sample - loss: 1.4262 - accuracy: 0.4892 - val_loss: 1.4160 - val_accuracy: 0.4892\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 35s 871us/sample - loss: 1.4222 - accuracy: 0.4908 - val_loss: 1.4150 - val_accuracy: 0.4938\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 38s 943us/sample - loss: 1.4110 - accuracy: 0.4940 - val_loss: 1.4359 - val_accuracy: 0.4894\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 34s 851us/sample - loss: 1.4005 - accuracy: 0.4990 - val_loss: 1.4832 - val_accuracy: 0.4736\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 40s 999us/sample - loss: 1.3942 - accuracy: 0.4978 - val_loss: 1.4638 - val_accuracy: 0.4820\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 39s 979us/sample - loss: 1.3862 - accuracy: 0.5014 - val_loss: 1.4916 - val_accuracy: 0.4669\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 40s 993us/sample - loss: 1.3775 - accuracy: 0.5067 - val_loss: 1.4656 - val_accuracy: 0.4840\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 39s 972us/sample - loss: 1.3647 - accuracy: 0.5088 - val_loss: 1.5014 - val_accuracy: 0.4670\n",
      "10000/10000 [==============================] - 4s 388us/sample - loss: 1.5014 - accuracy: 0.4670\n",
      "Fold validation loss:  1.501363377571106\n",
      "Fold validation accuracy:  0.467\n",
      "10000/10000 [==============================] - 4s 441us/sample - loss: 1.6197 - accuracy: 0.4367\n",
      "Test loss:  1.6197061590194701\n",
      "Test accuracy:  0.4367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(256, activation='relu', input_shape=(3072,)))\n",
    "model3.add(layers.Dense(256, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, val_index in kf.split(x_train):\n",
    "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Train the model\n",
    "    # model.fit(x_train_fold, y_train_fold, epochs=100, batch_size=128)\n",
    "    model3.fit(x_train_fold, y_train_fold, epochs=10, batch_size=32, validation_data=(x_val_fold, y_val_fold))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss, val_acc = model3.evaluate(x_val_fold, y_val_fold)\n",
    "    print(\"Fold validation loss: \", val_loss)\n",
    "    print(\"Fold validation accuracy: \", val_acc)\n",
    "\n",
    "test_loss, test_acc = model3.evaluate(x_test, y_test)\n",
    "print(\"Test loss: \", test_loss)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mobile phone does not haver the required computaitonal power, memory specifications, performance required to train and use a deep neural network since a mobile has limited specifications. We cannot train a FCNN (deep on a mobile phone therefore.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
