{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgvWFzN_XwWj"
   },
   "source": [
    "## Q1. Housing Price (SVM/SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUdNSpZTX53n"
   },
   "source": [
    "#### Load and Explore the Data\n",
    "\n",
    "*   Think about standardizing the data.\n",
    "\n",
    "*  How would you replace discrete attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "id": "Qg7N_4M3XuSX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>land</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>bldtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2607</td>\n",
       "      <td>1200</td>\n",
       "      <td>2010</td>\n",
       "      <td>825000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>1783</td>\n",
       "      <td>1899</td>\n",
       "      <td>1685000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2520</td>\n",
       "      <td>1875</td>\n",
       "      <td>1899</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3750</td>\n",
       "      <td>3125</td>\n",
       "      <td>1931</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7812</td>\n",
       "      <td>5021</td>\n",
       "      <td>1908</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  land  year      price  bldtype\n",
       "0  2607  1200  2010   825000.0        0\n",
       "1  1950  1783  1899  1685000.0        0\n",
       "2  2520  1875  1899  1100000.0        0\n",
       "3  3750  3125  1931  1200000.0        1\n",
       "4  7812  5021  1908  1900000.0        1"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lab3_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1918.031914893617"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the mean value of year, We will update the features to 'Modern' and 'Legacy' based on after or before the year 1918."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>land</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>bldtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2607</td>\n",
       "      <td>1200</td>\n",
       "      <td>Modern</td>\n",
       "      <td>825000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>1783</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>1685000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2520</td>\n",
       "      <td>1875</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3750</td>\n",
       "      <td>3125</td>\n",
       "      <td>Modern</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7812</td>\n",
       "      <td>5021</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  land    year      price  bldtype\n",
       "0  2607  1200  Modern   825000.0        0\n",
       "1  1950  1783  Legacy  1685000.0        0\n",
       "2  2520  1875  Legacy  1100000.0        0\n",
       "3  3750  3125  Modern  1200000.0        1\n",
       "4  7812  5021  Legacy  1900000.0        1"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'] = np.where(df['year'] >= 1918, 'Modern', 'Legacy')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pd.get_dummies(df['year'])\n",
    "df = df.drop('year', axis=1)\n",
    "df = df.join(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>land</th>\n",
       "      <th>price</th>\n",
       "      <th>bldtype</th>\n",
       "      <th>Legacy</th>\n",
       "      <th>Modern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2607</td>\n",
       "      <td>1200</td>\n",
       "      <td>825000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>1783</td>\n",
       "      <td>1685000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2520</td>\n",
       "      <td>1875</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3750</td>\n",
       "      <td>3125</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7812</td>\n",
       "      <td>5021</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  land      price  bldtype  Legacy  Modern\n",
       "0  2607  1200   825000.0        0       0       1\n",
       "1  1950  1783  1685000.0        0       1       0\n",
       "2  2520  1875  1100000.0        0       1       0\n",
       "3  3750  3125  1200000.0        1       0       1\n",
       "4  7812  5021  1900000.0        1       1       0"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['area', 'land', 'price', 'Legacy', 'Modern']]\n",
    "y = df.loc[:, 'bldtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_subset = scaler.fit_transform(X_train.iloc[:,0:3])\n",
    "X_last_column = X_train.iloc[:, 3:]\n",
    "X_trainf = np.concatenate((X_subset, X_last_column), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset2 = scaler.transform(X_test.iloc[:,0:3])\n",
    "X_last_column2 = X_test.iloc[:, 3:]\n",
    "X_testf = np.concatenate((X_subset2, X_last_column2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to scale and standardize our data such that all the data points under different parameters fall on the same scale.\n",
    "\n",
    "For us to replace discrete attributes, we can either rename them to some categorical columns, or we can perform encoding on these columns.\n",
    "\n",
    "\n",
    "1. One Hot Encoding allows each value to take 1 where the class exists and 0 elsewhere. This prevents the data from getting ordinally encoded giving the classes equal weightage.\n",
    "\n",
    "2. We can also perform Label or Binary Encoding to our classes however, in case of discrete columns, they take an ordinal value which is not representative of the class. If we have Cat and Dog as two classes, Label encoding would assign them values 0 and 1 which would introduce some type of bias to the data.\n",
    "\n",
    "3. In this dataset, the discrete value of Year was updated to fit the categories 'Modern' or 'Legacy' based on when hey were built. We can now get dummies or One Hot Encode this column.\n",
    "\n",
    "4. We can also choose to add the age of the house based on the year built, that is also a good way of removing discrete data.\n",
    "\n",
    "5. We only scale the columns which have a huge range in their values. Therefore we do not scale our one hot encoded columns only the first 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MC7mAvEYi77"
   },
   "source": [
    "#### Train a linear model with soft margin\n",
    "\n",
    "\n",
    "\n",
    "*   Try with initial value of C=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "id": "g1Y4XOosYw1W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.0 or: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1,kernel='linear', random_state=42)\n",
    "svc.fit(X_trainf, y_train)\n",
    "y_pred = svc.predict(X_testf)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy is:', accuracy, \"or:\", accuracy * 100,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Crsr5tYxgZ"
   },
   "source": [
    "#### Use cross validation to find best value of C\n",
    "\n",
    "\n",
    "\n",
    "*   Can do it manually or use GridSearchCV\n",
    "\n",
    "*   Divide the training set into train+validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "id": "gvdhwf8-ZESy"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_trainf, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6.828828828828828}\n"
     ]
    }
   ],
   "source": [
    "c = {'C':np.linspace(1,10,1000)}\n",
    "modelSVC = GridSearchCV(svc, c)\n",
    "modelSVC.fit(X_trainf, y_train)\n",
    "print(modelSVC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnoFPiELZH95"
   },
   "source": [
    "#### Analyse accuracy basis the new values you have computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "id": "k-xThyb7ZL58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "y_val_preds = modelSVC.predict(X_val)\n",
    "print('Accuracy is', accuracy_score(y_val_preds, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data with updated C is 100.0\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = modelSVC.predict(X_testf)\n",
    "print('Accuracy on test data with updated C is', accuracy_score(y_test_preds, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv6fi6bzZOfk"
   },
   "source": [
    "## Q2. DT and RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vckl9zaSaFkr"
   },
   "source": [
    "Consider the Wisconsin Breast Cancer dataset available from\n",
    "http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+\n",
    "(Diagnostic)\n",
    "\n",
    "The dataset has 32 attributes that predict malignancy. There are a\n",
    "total of 569 data patterns. Use 5-fold cross-validation. \n",
    "\n",
    "\n",
    "1.   Use Keras or any other framework to construct a decision tree from the training data and obtain the performance on the test data\n",
    "\n",
    "2.   Construct a random forest (of say, 100 trees) from the training data and use the random forest to obtain the performance on the test data\n",
    "\n",
    "3. Compare the performance you obtain in 1 and 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "id": "aIti5UQnZRA5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>85922302</td>\n",
       "      <td>M</td>\n",
       "      <td>12.680</td>\n",
       "      <td>23.84</td>\n",
       "      <td>82.69</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.12620</td>\n",
       "      <td>0.11280</td>\n",
       "      <td>0.06873</td>\n",
       "      <td>...</td>\n",
       "      <td>33.47</td>\n",
       "      <td>111.80</td>\n",
       "      <td>888.3</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>0.40610</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.17160</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.10310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>859283</td>\n",
       "      <td>M</td>\n",
       "      <td>14.780</td>\n",
       "      <td>23.94</td>\n",
       "      <td>97.40</td>\n",
       "      <td>668.3</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.12670</td>\n",
       "      <td>0.09029</td>\n",
       "      <td>...</td>\n",
       "      <td>33.39</td>\n",
       "      <td>114.60</td>\n",
       "      <td>925.1</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.34160</td>\n",
       "      <td>0.30240</td>\n",
       "      <td>0.16140</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.08911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>859464</td>\n",
       "      <td>B</td>\n",
       "      <td>9.465</td>\n",
       "      <td>21.01</td>\n",
       "      <td>60.11</td>\n",
       "      <td>269.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.02172</td>\n",
       "      <td>0.01504</td>\n",
       "      <td>...</td>\n",
       "      <td>31.56</td>\n",
       "      <td>67.03</td>\n",
       "      <td>330.7</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.16640</td>\n",
       "      <td>0.09412</td>\n",
       "      <td>0.06517</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.09211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>859465</td>\n",
       "      <td>B</td>\n",
       "      <td>11.310</td>\n",
       "      <td>19.04</td>\n",
       "      <td>71.80</td>\n",
       "      <td>394.1</td>\n",
       "      <td>0.08139</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>0.03709</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>...</td>\n",
       "      <td>23.84</td>\n",
       "      <td>78.00</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.09148</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.06961</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.06641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>859471</td>\n",
       "      <td>B</td>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>...</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M       17.990         10.38          122.80     1001.0   \n",
       "1     842517         M       20.570         17.77          132.90     1326.0   \n",
       "2   84300903         M       19.690         21.25          130.00     1203.0   \n",
       "3   84348301         M       11.420         20.38           77.58      386.1   \n",
       "4   84358402         M       20.290         14.34          135.10     1297.0   \n",
       "..       ...       ...          ...           ...             ...        ...   \n",
       "64  85922302         M       12.680         23.84           82.69      499.0   \n",
       "65    859283         M       14.780         23.94           97.40      668.3   \n",
       "66    859464         B        9.465         21.01           60.11      269.4   \n",
       "67    859465         B       11.310         19.04           71.80      394.1   \n",
       "68    859471         B        9.029         17.33           58.79      250.5   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "..              ...               ...             ...                  ...   \n",
       "64          0.11220           0.12620         0.11280              0.06873   \n",
       "65          0.11720           0.14790         0.12670              0.09029   \n",
       "66          0.10440           0.07773         0.02172              0.01504   \n",
       "67          0.08139           0.04701         0.03709              0.02230   \n",
       "68          0.10660           0.14130         0.31300              0.04375   \n",
       "\n",
       "    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0   ...          17.33           184.60      2019.0            0.1622   \n",
       "1   ...          23.41           158.80      1956.0            0.1238   \n",
       "2   ...          25.53           152.50      1709.0            0.1444   \n",
       "3   ...          26.50            98.87       567.7            0.2098   \n",
       "4   ...          16.67           152.20      1575.0            0.1374   \n",
       "..  ...            ...              ...         ...               ...   \n",
       "64  ...          33.47           111.80       888.3            0.1851   \n",
       "65  ...          33.39           114.60       925.1            0.1648   \n",
       "66  ...          31.56            67.03       330.7            0.1548   \n",
       "67  ...          23.84            78.00       466.7            0.1290   \n",
       "68  ...          22.65            65.50       324.7            0.1482   \n",
       "\n",
       "    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.66560          0.71190               0.26540          0.4601   \n",
       "1             0.18660          0.24160               0.18600          0.2750   \n",
       "2             0.42450          0.45040               0.24300          0.3613   \n",
       "3             0.86630          0.68690               0.25750          0.6638   \n",
       "4             0.20500          0.40000               0.16250          0.2364   \n",
       "..                ...              ...                   ...             ...   \n",
       "64            0.40610          0.40240               0.17160          0.3383   \n",
       "65            0.34160          0.30240               0.16140          0.3321   \n",
       "66            0.16640          0.09412               0.06517          0.2878   \n",
       "67            0.09148          0.14440               0.06961          0.2400   \n",
       "68            0.43650          1.25200               0.17500          0.4228   \n",
       "\n",
       "    fractal_dimension_worst  Unnamed: 32  \n",
       "0                   0.11890          NaN  \n",
       "1                   0.08902          NaN  \n",
       "2                   0.08758          NaN  \n",
       "3                   0.17300          NaN  \n",
       "4                   0.07678          NaN  \n",
       "..                      ...          ...  \n",
       "64                  0.10310          NaN  \n",
       "65                  0.08911          NaN  \n",
       "66                  0.09211          NaN  \n",
       "67                  0.06641          NaN  \n",
       "68                  0.11750          NaN  \n",
       "\n",
       "[69 rows x 33 columns]"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "df = pd.read_csv('dataWisconsin.csv')\n",
    "df.head(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 32', inplace=True, axis=1)\n",
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = df.iloc[:, 1:], df.loc[:, 'diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DTC = DTC()\n",
    "max_dep = {'max_depth':np.arange(2,10)}\n",
    "modelCV = GridSearchCV(model_DTC, max_dep, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classification is 93.85964912280701 %\n"
     ]
    }
   ],
   "source": [
    "modelCV.fit(X_train, y_train)\n",
    "y_pred = modelCV.predict(X_test)\n",
    "print('Accuracy of classification is', accuracy_score(y_pred, y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k4nskDtafj_"
   },
   "source": [
    "####  Repeat the exercise but add ±10% noise to 25% of the data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "id": "l-4Mc8bxakpN"
   },
   "outputs": [],
   "source": [
    "X, y = df.iloc[:, 1:], df.loc[:, 'diagnosis']\n",
    "noise_df = X.sample(frac=0.25)\n",
    "#noise = ((np.random.randint(-10,10)) * noise_df)\n",
    "#noise_df = noise_df + noise\n",
    "noise_df = noise_df + ((np.random.randint(-10,10)/100)* noise_df)\n",
    "X.update(noise_df)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>8.30668</td>\n",
       "      <td>15.9436</td>\n",
       "      <td>54.0868</td>\n",
       "      <td>230.46</td>\n",
       "      <td>0.098072</td>\n",
       "      <td>0.129996</td>\n",
       "      <td>0.28796</td>\n",
       "      <td>0.04025</td>\n",
       "      <td>0.194212</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4852</td>\n",
       "      <td>20.838</td>\n",
       "      <td>60.26</td>\n",
       "      <td>298.724</td>\n",
       "      <td>0.136344</td>\n",
       "      <td>0.40158</td>\n",
       "      <td>1.15184</td>\n",
       "      <td>0.16100</td>\n",
       "      <td>0.388976</td>\n",
       "      <td>0.10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>21.09000</td>\n",
       "      <td>26.5700</td>\n",
       "      <td>142.7000</td>\n",
       "      <td>1311.00</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.073980</td>\n",
       "      <td>...</td>\n",
       "      <td>26.6800</td>\n",
       "      <td>33.480</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.000</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9.17300</td>\n",
       "      <td>13.8600</td>\n",
       "      <td>59.2000</td>\n",
       "      <td>260.90</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.069630</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0100</td>\n",
       "      <td>19.230</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.100</td>\n",
       "      <td>0.098360</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10.65000</td>\n",
       "      <td>25.2200</td>\n",
       "      <td>68.0100</td>\n",
       "      <td>347.00</td>\n",
       "      <td>0.096570</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2500</td>\n",
       "      <td>35.190</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.700</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.17000</td>\n",
       "      <td>14.8800</td>\n",
       "      <td>64.5500</td>\n",
       "      <td>311.90</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0200</td>\n",
       "      <td>17.450</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.600</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8.88800</td>\n",
       "      <td>14.6400</td>\n",
       "      <td>58.7900</td>\n",
       "      <td>244.00</td>\n",
       "      <td>0.097830</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7330</td>\n",
       "      <td>15.670</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.400</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.14340</td>\n",
       "      <td>0.04786</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.64000</td>\n",
       "      <td>18.3300</td>\n",
       "      <td>75.1700</td>\n",
       "      <td>412.50</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1400</td>\n",
       "      <td>29.260</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.700</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.28730</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.09097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>14.29000</td>\n",
       "      <td>16.8200</td>\n",
       "      <td>90.3000</td>\n",
       "      <td>632.60</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>0.026750</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.053760</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9100</td>\n",
       "      <td>20.650</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.600</td>\n",
       "      <td>0.085670</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.06120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>13.98000</td>\n",
       "      <td>19.6200</td>\n",
       "      <td>91.1200</td>\n",
       "      <td>599.50</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.06463</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.065440</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0400</td>\n",
       "      <td>30.800</td>\n",
       "      <td>113.90</td>\n",
       "      <td>869.300</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.35680</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.18000</td>\n",
       "      <td>20.5200</td>\n",
       "      <td>77.2200</td>\n",
       "      <td>458.70</td>\n",
       "      <td>0.080130</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>...</td>\n",
       "      <td>13.3400</td>\n",
       "      <td>32.840</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.800</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.06878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "68       8.30668       15.9436         54.0868     230.46         0.098072   \n",
       "181     21.09000       26.5700        142.7000    1311.00         0.114100   \n",
       "63       9.17300       13.8600         59.2000     260.90         0.077210   \n",
       "248     10.65000       25.2200         68.0100     347.00         0.096570   \n",
       "60      10.17000       14.8800         64.5500     311.90         0.113400   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "71       8.88800       14.6400         58.7900     244.00         0.097830   \n",
       "106     11.64000       18.3300         75.1700     412.50         0.114200   \n",
       "270     14.29000       16.8200         90.3000     632.60         0.064290   \n",
       "435     13.98000       19.6200         91.1200     599.50         0.106000   \n",
       "102     12.18000       20.5200         77.2200     458.70         0.080130   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "68           0.129996         0.28796              0.04025       0.194212   \n",
       "181          0.283200         0.24870              0.14960       0.239500   \n",
       "63           0.087510         0.05988              0.02180       0.234100   \n",
       "248          0.072340         0.02379              0.01615       0.189700   \n",
       "60           0.080610         0.01084              0.01290       0.274300   \n",
       "..                ...             ...                  ...            ...   \n",
       "71           0.153100         0.08606              0.02872       0.190200   \n",
       "106          0.101700         0.07070              0.03485       0.180100   \n",
       "270          0.026750         0.00725              0.00625       0.150800   \n",
       "435          0.113300         0.11260              0.06463       0.166900   \n",
       "102          0.040380         0.02383              0.01770       0.173900   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "68                 0.074023  ...        9.4852         20.838   \n",
       "181                0.073980  ...       26.6800         33.480   \n",
       "63                 0.069630  ...       10.0100         19.230   \n",
       "248                0.063290  ...       12.2500         35.190   \n",
       "60                 0.069600  ...       11.0200         17.450   \n",
       "..                      ...  ...           ...            ...   \n",
       "71                 0.089800  ...        9.7330         15.670   \n",
       "106                0.065200  ...       13.1400         29.260   \n",
       "270                0.053760  ...       14.9100         20.650   \n",
       "435                0.065440  ...       17.0400         30.800   \n",
       "102                0.056770  ...       13.3400         32.840   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "68             60.26     298.724          0.136344            0.40158   \n",
       "181           176.50    2089.000          0.149100            0.75840   \n",
       "63             65.59     310.100          0.098360            0.16780   \n",
       "248            77.98     455.700          0.149900            0.13980   \n",
       "60             69.86     368.600          0.127500            0.09866   \n",
       "..               ...         ...               ...                ...   \n",
       "71             62.56     284.400          0.120700            0.24360   \n",
       "106            85.51     521.700          0.168800            0.26600   \n",
       "270            94.44     684.600          0.085670            0.05036   \n",
       "435           113.90     869.300          0.161300            0.35680   \n",
       "102            84.58     547.800          0.112300            0.08862   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "68           1.15184               0.16100        0.388976   \n",
       "181          0.67800               0.29030        0.409800   \n",
       "63           0.13970               0.05087        0.328200   \n",
       "248          0.11250               0.06136        0.340900   \n",
       "60           0.02168               0.02579        0.355700   \n",
       "..               ...                   ...             ...   \n",
       "71           0.14340               0.04786        0.225400   \n",
       "106          0.28730               0.12180        0.280600   \n",
       "270          0.03866               0.03333        0.245800   \n",
       "435          0.40690               0.18270        0.317900   \n",
       "102          0.11450               0.07431        0.269400   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "68                   0.10810  \n",
       "181                  0.12840  \n",
       "63                   0.08490  \n",
       "248                  0.08147  \n",
       "60                   0.08020  \n",
       "..                       ...  \n",
       "71                   0.10840  \n",
       "106                  0.09097  \n",
       "270                  0.06120  \n",
       "435                  0.10550  \n",
       "102                  0.06878  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classification is 94.73684210526315 %\n"
     ]
    }
   ],
   "source": [
    "model_DTC = DTC(random_state=42)\n",
    "max_dep = {'max_depth':np.arange(2,10)}\n",
    "modelCV = GridSearchCV(model_DTC, max_dep, cv=5)\n",
    "modelCV.fit(X_train, y_train)\n",
    "y_pred = modelCV.predict(X_test)\n",
    "print('Accuracy of classification is', accuracy_score(y_pred, y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest of 100 trees is: 96.49122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc1 = RandomForestClassifier(n_estimators=100, max_depth = 4)\n",
    "rfc1.fit(X_train, y_train)\n",
    "y_predRF = rfc1.predict(X_test)\n",
    "print('Accuracy with Random Forest of 100 trees is:', accuracy_score(y_predRF, y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with 100 trees is a bagging approach that combines the predictions of all the 100 tres, votes on their predictions and gives the final decided class. It is therefore better than Decision Tree(single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qy9n-nOFrJIC"
   },
   "source": [
    "### Boosting\n",
    "\n",
    "Implement a boosting classifier algorithm for the same dataset as above (sample without noise)\n",
    "\n",
    "Feel free to use any boosting algorithm you want\n",
    "\n",
    "However only run the code for the eventual algorithm you choose and comment out every other algorithm\n",
    "\n",
    "Briefly explain why you chose a particular algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "id": "2TqA4iczrKYv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  97.36842105263158\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 3)\n",
    "abc = AdaBoostClassifier(dtc, n_estimators=100)\n",
    "abc.fit(X_train, y_train)\n",
    "y_hat = abc.predict(X_test)\n",
    "print('Accuracy Score = ', accuracy_score(y_hat, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "# gbc.fit(X_train2, y_train2)\n",
    "# y_hat = abc.predict(X_test2)\n",
    "# print('Accuracy Score = ', accuracy_score(y_hat, y_test2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_update = np.where(y_train2 == 'B', 0, 1)\n",
    "# y_test_update = np.where(y_test2 == 'B', 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost = xgb.XGBClassifier(n_estimators=100, max_depth = 3)\n",
    "# xgboost.fit(X_train, y_train_update)\n",
    "# y_hat = xgboost.predict(X_test)\n",
    "# print('Accuracy Score = ', accuracy_score(y_hat, y_test_update)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of Boosting Algorithm\n",
    "\n",
    "I used several Boosting algorithms but went ahead with AdaBoost(Adaptive Boosting) algorithm.\n",
    "AdaBoost uses decision trees as their base classifiers while XgBoost uses a gradient boosting as base estimator. AdaBoost is not sensitive to noisy dta which was added above and is able to generalise well over a large number of features.\n",
    "\n",
    "AdaBoost (Adaptive Boosting) is a type of boosting algorithm that can handle noisy data and a large number of features well. Boosting algorithms work by combining the predictions of multiple weak models to create a strong, accurate model. AdaBoost works by training a series of weak models, each of which is a decision tree. The decision trees are trained sequentially, with the focus on the examples that were misclassified by the previous tree.\n",
    "Each tree in the ensemble is trained on a modified version of the original data set, where the weights of the misclassified examples are increased so that the next tree pays more attention to them. This allows the algorithm to focus on the most important examples and helps to reduce the impact of noise in the data.\n",
    "\n",
    "In terms of handling a large number of features, AdaBoost is able to handle high-dimensional data well because decision trees are able to effectively handle large numbers of features. Decision trees are able to find the most important features and split the data based on those features, which allows them to effectively handle high-dimensional data.\n",
    "\n",
    "Overall, AdaBoost is a good choice for handling noisy data and a large number of features. It is able to effectively learn from the data and create a strong, accurate model by combining the predictions of multiple weak models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsEMVq_wyqJO"
   },
   "source": [
    "### Bagging\n",
    "\n",
    "Implement a bagging classifier on the RF you created above\n",
    "\n",
    "\n",
    "> from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "You will have to pass the DT into the Bagging Classifier\n",
    "\n",
    "Once you have the y_pred for Bagging and RF, accurately compute the accuracy by computing the numpy sum where pred(bagging) == pred(RF) and divide by len(pred(bagging))\n",
    "\n",
    "Please provide rationale behind why this is done.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "id": "AFwD6cjpzupM"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging Classifier is: 0.956140350877193\n",
      "Accuracy for Random Forest is: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "dtc2 = DecisionTreeClassifier(max_depth=4)\n",
    "bg = BaggingClassifier(dtc2, n_estimators=100, max_samples = 0.45)\n",
    "rfc = RandomForestClassifier(n_estimators = 100, max_depth = 3, random_state=42)\n",
    "bg.fit(X_train, y_train)\n",
    "y_hat_bg = bg.predict(X_test)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_hat_rfc = rfc.predict(X_test)\n",
    "print('Accuracy with Bagging Classifier is:', accuracy_score(y_hat_bg, y_test))\n",
    "print('Accuracy for Random Forest is:', accuracy_score(y_hat_rfc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_bg = accuracy_score(y_hat_bg, y_test)\n",
    "acc_rfc =  accuracy_score(y_hat_rfc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy by combining and comparing both classifiers predictions is :  99.12280701754386 %\n"
     ]
    }
   ],
   "source": [
    "s = len(np.where(y_hat_bg==y_hat_rfc)[0])\n",
    "final_acc = (s/len(y_hat_bg))*100\n",
    "print('Final accuracy by combining and comparing both classifiers predictions is : ', final_acc, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method's rationale is that it enables you to compare the performance of the two models by counting the instances in which their predictions coincide. Similar predictions from the models suggest that they are working effectively and accurately. On the other side, if the models' projections are considerably disagreeing, it can mean that one or both of the models are underperforming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJj8c79e0JUr"
   },
   "source": [
    "Bonus : While you are looking at ensemble models, explore VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Voting classifier with 3 estimators is:  96.49122807017544 %\n",
      "Accuracy for Voting classifier with 5 estimators is:  95.6140350877193 %\n",
      "Accuracy for Voting classifier with 3 best estimators is:  96.49122807017544 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf1 = modelCV\n",
    "clf2 = abc\n",
    "clf3 = gbc\n",
    "clf4 = bg\n",
    "clf5 = rfc\n",
    "clf6 = SVC(kernel = 'poly', degree=7,probability=True)\n",
    "clf7 = GaussianNB()\n",
    "eclf1 = VotingClassifier(estimators = [('CVDTC',clf1), ('Naive Bayes',clf7), ('RandomForestClassifier', clf5)], voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "voting_pred1 = eclf1.predict(X_test)\n",
    "eclf2 = VotingClassifier(estimators=[('CVDTC', clf1), ('AdaBoost', clf2), ('GradientBoosting', clf3), ('BaggingClasifier', clf4),\n",
    "                                    ('RandomForestClassifier', clf5)], voting='soft')\n",
    "eclf2.fit(X_train, y_train)\n",
    "voting_pred2 = eclf2.predict(X_test)\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[('BaggingClasifier', clf4),\n",
    "                                    ('RandomForestClassifier', clf5), ('SVM', clf6)], voting='soft')\n",
    "eclf3.fit(X_train, y_train)\n",
    "voting_pred3 = eclf3.predict(X_test)\n",
    "print('Accuracy for Voting classifier with 3 estimators is: ', accuracy_score(voting_pred1, y_test2)*100,\"%\")\n",
    "print('Accuracy for Voting classifier with 5 estimators is: ', accuracy_score(voting_pred2, y_test2)*100,\"%\")\n",
    "print('Accuracy for Voting classifier with 3 best estimators is: ', accuracy_score(voting_pred3, y_test2)*100,\"%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
